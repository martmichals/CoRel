import os, argparse

# Converts the CoRel output file structure into a taxonomy file matching the format of the TaxoCom output
def main(args):
    # Function variables
    corel_data_dir = './'
    corpus = args.corpus
    output_path = args.output

    # Check that the output root directory exists
    res_dir = os.path.join(os.path.join(corel_data_dir, 'result'), corpus)
    if not os.path.isdir(res_dir): 
        raise ValueError('Model did not generate output correctly. Expected root folder for output taxonomy {} does not exist'.format(res_dir))

    # Get the first level of topics
    first_level_topics = set()
    with open(os.path.join(os.path.join(res_dir, 'firstlayer'), 'subtopics_firstlayer.txt'), 'r') as f:
        for line in f:
            first_level_topics.add(frozenset(line.split()))

    # Get the representative terms for all of the first level topics, reorganize first layer into a dictionary
    first_level_topics_dirs = set(next(os.walk(res_dir))[1])
    first_level_topics_dirs.remove('firstlayer')
    if len(first_level_topics_dirs) != len(first_level_topics):
        raise ValueError(
            'Model did not generate output correctly. The number of topics in the second layer of output, {}, does not match expectation, {}'.format(len(first_level_topics_dirs), len(first_level_topics))
        )
    first_level_topic_dict = {}
    taken_clusters = set()
    for rep_phrase in first_level_topics_dirs:
        for word_cluster in first_level_topics:
            if rep_phrase in word_cluster:
                first_level_topic_dict[rep_phrase] = word_cluster
                taken_clusters.add(word_cluster)

    # Match to try and find the most likely cluster for the word if does not appear in any cluster
    for rep_phrase in first_level_topics_dirs:
        if rep_phrase not in first_level_topic_dict:
            matches_max, cluster = -1, None
            for word_cluster in first_level_topics:
                if word_cluster not in taken_clusters:
                    match_cnt = sum([1 if rep_phrase in term else 0 for term in word_cluster])
                    if match_cnt > matches_max:
                        matches_max = match_cnt
                        cluster = word_cluster
            first_level_topic_dict[rep_phrase] = cluster
            taken_clusters.add(cluster)

    # Get second layer clusters
    second_layer_topics = {}
    for rep_phrase in first_level_topics_dirs:
        subtopic_file = os.path.join(os.path.join(res_dir, rep_phrase), 'subtopics_{}.txt'.format(rep_phrase))
        print(subtopic_file)
        with open(subtopic_file, 'r') as f:
            phrase_clusters = [[phrase for phrase in line.split()] for line in f]
            second_layer_topics[rep_phrase] = phrase_clusters

    # Save the output taxonomy to the output path
    with open(output_path, 'w') as out_f:
        # First level of topics
        for topic in first_level_topic_dict:
            out_f.write('*/{} '.format(topic))
            out_f.write('{}\n'.format(','.join(first_level_topic_dict[topic])))
        # Second level of topics
        for topic in first_level_topic_dict:
            for cluster in second_layer_topics[topic]:
                out_f.write('*/{}/{} '.format(topic, cluster[0]))
                out_f.write('{}\n'.format(','.join(cluster[1:])))

if __name__ == '__main__':
    # Initialize argument parser
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--corpus',
        type=str, 
        default='dblp',
        help='Which corpus to run the post-processing on.'
    )
    parser.add_argument(
        '--output',
        type=str, 
        default='output_taxonomy.txt',
        help='Filepath for the output taxonomy generated by the script.'
    )

    # Parse arguments
    args = parser.parse_args()
    print(args)
    main(args)
